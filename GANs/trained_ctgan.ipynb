{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CTGAN module.\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import BatchNorm1d, Dropout, LeakyReLU, Linear, Module, ReLU, Sequential, functional\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ctgan.data_sampler import DataSampler\n",
    "from ctgan.data_transformer import DataTransformer\n",
    "from ctgan.errors import InvalidDataError\n",
    "from ctgan.synthesizers.base import BaseSynthesizer, random_state\n",
    "\n",
    "\n",
    "class Discriminator(Module):\n",
    "    \"\"\"Discriminator for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, discriminator_dim, pac=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        dim = input_dim * pac\n",
    "        self.pac = pac\n",
    "        self.pacdim = dim\n",
    "        seq = []\n",
    "        for item in list(discriminator_dim):\n",
    "            seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
    "            dim = item\n",
    "\n",
    "        seq += [Linear(dim, 1)]\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
    "        \"\"\"Compute the gradient penalty.\"\"\"\n",
    "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
    "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
    "        alpha = alpha.view(-1, real_data.size(1))\n",
    "\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "        disc_interpolates = self(interpolates)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=disc_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        gradients_view = gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
    "        gradient_penalty = ((gradients_view) ** 2).mean() * lambda_\n",
    "\n",
    "        return gradient_penalty\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Discriminator to the `input_`.\"\"\"\n",
    "        assert input_.size()[0] % self.pac == 0\n",
    "        return self.seq(input_.view(-1, self.pacdim))\n",
    "\n",
    "\n",
    "class Residual(Module):\n",
    "    \"\"\"Residual layer for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, i, o):\n",
    "        super(Residual, self).__init__()\n",
    "        self.fc = Linear(i, o)\n",
    "        self.bn = BatchNorm1d(o)\n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Residual layer to the `input_`.\"\"\"\n",
    "        out = self.fc(input_)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return torch.cat([out, input_], dim=1)\n",
    "\n",
    "\n",
    "class Generator(Module):\n",
    "    \"\"\"Generator for the CTGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, generator_dim, data_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        dim = embedding_dim\n",
    "        seq = []\n",
    "        for item in list(generator_dim):\n",
    "            seq += [Residual(dim, item)]\n",
    "            dim += item\n",
    "        seq.append(Linear(dim, data_dim))\n",
    "        self.seq = Sequential(*seq)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        \"\"\"Apply the Generator to the `input_`.\"\"\"\n",
    "        data = self.seq(input_)\n",
    "        return data\n",
    "\n",
    "\n",
    "class CTGAN(BaseSynthesizer):\n",
    "    \"\"\"Conditional Table GAN Synthesizer.\n",
    "\n",
    "    This is the core class of the CTGAN project, where the different components\n",
    "    are orchestrated together.\n",
    "    For more details about the process, please check the [Modeling Tabular data using\n",
    "    Conditional GAN](https://arxiv.org/abs/1907.00503) paper.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int):\n",
    "            Size of the random sample passed to the Generator. Defaults to 128.\n",
    "        generator_dim (tuple or list of ints):\n",
    "            Size of the output samples for each one of the Residuals. A Residual Layer\n",
    "            will be created for each one of the values provided. Defaults to (256, 256).\n",
    "        discriminator_dim (tuple or list of ints):\n",
    "            Size of the output samples for each one of the Discriminator Layers. A Linear Layer\n",
    "            will be created for each one of the values provided. Defaults to (256, 256).\n",
    "        generator_lr (float):\n",
    "            Learning rate for the generator. Defaults to 2e-4.\n",
    "        generator_decay (float):\n",
    "            Generator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
    "        discriminator_lr (float):\n",
    "            Learning rate for the discriminator. Defaults to 2e-4.\n",
    "        discriminator_decay (float):\n",
    "            Discriminator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
    "        batch_size (int):\n",
    "            Number of data samples to process in each step.\n",
    "        discriminator_steps (int):\n",
    "            Number of discriminator updates to do for each generator update.\n",
    "            From the WGAN paper: https://arxiv.org/abs/1701.07875. WGAN paper\n",
    "            default is 5. Default used is 1 to match original CTGAN implementation.\n",
    "        log_frequency (boolean):\n",
    "            Whether to use log frequency of categorical levels in conditional\n",
    "            sampling. Defaults to ``True``.\n",
    "        verbose (boolean):\n",
    "            Whether to have print statements for progress results. Defaults to ``False``.\n",
    "        epochs (int):\n",
    "            Number of training epochs. Defaults to 300.\n",
    "        pac (int):\n",
    "            Number of samples to group together when applying the discriminator.\n",
    "            Defaults to 10.\n",
    "        cuda (bool):\n",
    "            Whether to attempt to use cuda for GPU computation.\n",
    "            If this is False or CUDA is not available, CPU will be used.\n",
    "            Defaults to ``True``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim=128,\n",
    "        generator_dim=(256, 256),\n",
    "        discriminator_dim=(256, 256),\n",
    "        generator_lr=2e-4,\n",
    "        generator_decay=1e-6,\n",
    "        discriminator_lr=2e-4,\n",
    "        discriminator_decay=1e-6,\n",
    "        batch_size=500,\n",
    "        discriminator_steps=1,\n",
    "        log_frequency=True,\n",
    "        verbose=False,\n",
    "        epochs=300,\n",
    "        pac=10,\n",
    "        cuda=True,\n",
    "    ):\n",
    "        assert batch_size % 2 == 0\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._generator_dim = generator_dim\n",
    "        self._discriminator_dim = discriminator_dim\n",
    "\n",
    "        self._generator_lr = generator_lr\n",
    "        self._generator_decay = generator_decay\n",
    "        self._discriminator_lr = discriminator_lr\n",
    "        self._discriminator_decay = discriminator_decay\n",
    "\n",
    "        self._batch_size = batch_size\n",
    "        self._discriminator_steps = discriminator_steps\n",
    "        self._log_frequency = log_frequency\n",
    "        self._verbose = verbose\n",
    "        self._epochs = epochs\n",
    "        self.pac = pac\n",
    "\n",
    "        if not cuda or not torch.cuda.is_available():\n",
    "            device = 'cpu'\n",
    "        elif isinstance(cuda, str):\n",
    "            device = cuda\n",
    "        else:\n",
    "            device = 'cuda'\n",
    "\n",
    "        self._device = torch.device(device)\n",
    "\n",
    "        self._transformer = None\n",
    "        self._data_sampler = None\n",
    "        self._generator = None\n",
    "        self._discriminator = None\n",
    "        self.loss_values = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
    "        \"\"\"Deals with the instability of the gumbel_softmax for older versions of torch.\n",
    "\n",
    "        For more details about the issue:\n",
    "        https://drive.google.com/file/d/1AA5wPfZ1kquaRtVruCd6BiYZGcDeNxyP/view?usp=sharing\n",
    "\n",
    "        Args:\n",
    "            logits [â€¦, num_features]:\n",
    "                Unnormalized log probabilities\n",
    "            tau:\n",
    "                Non-negative scalar temperature\n",
    "            hard (bool):\n",
    "                If True, the returned samples will be discretized as one-hot vectors,\n",
    "                but will be differentiated as if it is the soft sample in autograd\n",
    "            dim (int):\n",
    "                A dimension along which softmax will be computed. Default: -1.\n",
    "\n",
    "        Returns:\n",
    "            Sampled tensor of same shape as logits from the Gumbel-Softmax distribution.\n",
    "        \"\"\"\n",
    "        for _ in range(10):\n",
    "            transformed = functional.gumbel_softmax(logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
    "            if not torch.isnan(transformed).any():\n",
    "                return transformed\n",
    "\n",
    "        raise ValueError('gumbel_softmax returning NaN.')\n",
    "\n",
    "    def _apply_activate(self, data):\n",
    "        \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
    "        data_t = []\n",
    "        st = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if span_info.activation_fn == 'tanh':\n",
    "                    ed = st + span_info.dim\n",
    "                    data_t.append(torch.tanh(data[:, st:ed]))\n",
    "                    st = ed\n",
    "                elif span_info.activation_fn == 'softmax':\n",
    "                    ed = st + span_info.dim\n",
    "                    transformed = self._gumbel_softmax(data[:, st:ed], tau=0.2)\n",
    "                    data_t.append(transformed)\n",
    "                    st = ed\n",
    "                else:\n",
    "                    raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
    "\n",
    "        return torch.cat(data_t, dim=1)\n",
    "\n",
    "    def _cond_loss(self, data, c, m):\n",
    "        \"\"\"Compute the cross entropy loss on the fixed discrete column.\"\"\"\n",
    "        loss = []\n",
    "        st = 0\n",
    "        st_c = 0\n",
    "        for column_info in self._transformer.output_info_list:\n",
    "            for span_info in column_info:\n",
    "                if len(column_info) != 1 or span_info.activation_fn != 'softmax':\n",
    "                    # not discrete column\n",
    "                    st += span_info.dim\n",
    "                else:\n",
    "                    ed = st + span_info.dim\n",
    "                    ed_c = st_c + span_info.dim\n",
    "                    tmp = functional.cross_entropy(\n",
    "                        data[:, st:ed], torch.argmax(c[:, st_c:ed_c], dim=1), reduction='none'\n",
    "                    )\n",
    "                    loss.append(tmp)\n",
    "                    st = ed\n",
    "                    st_c = ed_c\n",
    "\n",
    "        loss = torch.stack(loss, dim=1)  # noqa: PD013\n",
    "\n",
    "        return (loss * m).sum() / data.size()[0]\n",
    "\n",
    "    def _validate_discrete_columns(self, train_data, discrete_columns):\n",
    "        \"\"\"Check whether ``discrete_columns`` exists in ``train_data``.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, pd.DataFrame):\n",
    "            invalid_columns = set(discrete_columns) - set(train_data.columns)\n",
    "        elif isinstance(train_data, np.ndarray):\n",
    "            invalid_columns = []\n",
    "            for column in discrete_columns:\n",
    "                if column < 0 or column >= train_data.shape[1]:\n",
    "                    invalid_columns.append(column)\n",
    "        else:\n",
    "            raise TypeError('``train_data`` should be either pd.DataFrame or np.array.')\n",
    "\n",
    "        if invalid_columns:\n",
    "            raise ValueError(f'Invalid columns found: {invalid_columns}')\n",
    "\n",
    "    def _validate_null_data(self, train_data, discrete_columns):\n",
    "        \"\"\"Check whether null values exist in continuous ``train_data``.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, pd.DataFrame):\n",
    "            continuous_cols = list(set(train_data.columns) - set(discrete_columns))\n",
    "            any_nulls = train_data[continuous_cols].isna().any().any()\n",
    "        else:\n",
    "            continuous_cols = [i for i in range(train_data.shape[1]) if i not in discrete_columns]\n",
    "            any_nulls = pd.DataFrame(train_data)[continuous_cols].isna().any().any()\n",
    "\n",
    "        if any_nulls:\n",
    "            raise InvalidDataError(\n",
    "                'CTGAN does not support null values in the continuous training data. '\n",
    "                'Please remove all null values from your continuous training data.'\n",
    "            )\n",
    "\n",
    "    @random_state\n",
    "    def fit(self, train_data, discrete_columns=(), epochs=None):\n",
    "        \"\"\"Fit the CTGAN Synthesizer models to the training data.\n",
    "\n",
    "        Args:\n",
    "            train_data (numpy.ndarray or pandas.DataFrame):\n",
    "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
    "            discrete_columns (list-like):\n",
    "                List of discrete columns to be used to generate the Conditional\n",
    "                Vector. If ``train_data`` is a Numpy array, this list should\n",
    "                contain the integer indices of the columns. Otherwise, if it is\n",
    "                a ``pandas.DataFrame``, this list should contain the column names.\n",
    "        \"\"\"\n",
    "        self._validate_discrete_columns(train_data, discrete_columns)\n",
    "        self._validate_null_data(train_data, discrete_columns)\n",
    "\n",
    "        if epochs is None:\n",
    "            epochs = self._epochs\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                (\n",
    "                    '`epochs` argument in `fit` method has been deprecated and will be removed '\n",
    "                    'in a future version. Please pass `epochs` to the constructor instead'\n",
    "                ),\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        self._transformer = DataTransformer()\n",
    "        self._transformer.fit(train_data, discrete_columns)\n",
    "\n",
    "        train_data = self._transformer.transform(train_data)\n",
    "\n",
    "        self._data_sampler = DataSampler(\n",
    "            train_data, self._transformer.output_info_list, self._log_frequency\n",
    "        )\n",
    "\n",
    "        data_dim = self._transformer.output_dimensions\n",
    "\n",
    "        self._generator = Generator(\n",
    "            self._embedding_dim + self._data_sampler.dim_cond_vec(), self._generator_dim, data_dim\n",
    "        ).to(self._device)\n",
    "\n",
    "        discriminator = Discriminator(\n",
    "            data_dim + self._data_sampler.dim_cond_vec(), self._discriminator_dim, pac=self.pac\n",
    "        ).to(self._device)\n",
    "\n",
    "        optimizerG = optim.Adam(\n",
    "            self._generator.parameters(),\n",
    "            lr=self._generator_lr,\n",
    "            betas=(0.5, 0.9),\n",
    "            weight_decay=self._generator_decay,\n",
    "        )\n",
    "\n",
    "        optimizerD = optim.Adam(\n",
    "            discriminator.parameters(),\n",
    "            lr=self._discriminator_lr,\n",
    "            betas=(0.5, 0.9),\n",
    "            weight_decay=self._discriminator_decay,\n",
    "        )\n",
    "\n",
    "        mean = torch.zeros(self._batch_size, self._embedding_dim, device=self._device)\n",
    "        std = mean + 1\n",
    "\n",
    "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Generator Loss', 'Distriminator Loss'])\n",
    "\n",
    "        epoch_iterator = tqdm(range(epochs), disable=(not self._verbose))\n",
    "        if self._verbose:\n",
    "            description = 'Gen. ({gen:.2f}) | Discrim. ({dis:.2f})'\n",
    "            epoch_iterator.set_description(description.format(gen=0, dis=0))\n",
    "\n",
    "        steps_per_epoch = max(len(train_data) // self._batch_size, 1)\n",
    "        for i in epoch_iterator:\n",
    "            for id_ in range(steps_per_epoch):\n",
    "                for n in range(self._discriminator_steps):\n",
    "                    fakez = torch.normal(mean=mean, std=std)\n",
    "\n",
    "                    condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
    "                    if condvec is None:\n",
    "                        c1, m1, col, opt = None, None, None, None\n",
    "                        real = self._data_sampler.sample_data(\n",
    "                            train_data, self._batch_size, col, opt\n",
    "                        )\n",
    "                    else:\n",
    "                        c1, m1, col, opt = condvec\n",
    "                        c1 = torch.from_numpy(c1).to(self._device)\n",
    "                        m1 = torch.from_numpy(m1).to(self._device)\n",
    "                        fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "                        perm = np.arange(self._batch_size)\n",
    "                        np.random.shuffle(perm)\n",
    "                        real = self._data_sampler.sample_data(\n",
    "                            train_data, self._batch_size, col[perm], opt[perm]\n",
    "                        )\n",
    "                        c2 = c1[perm]\n",
    "\n",
    "                    fake = self._generator(fakez)\n",
    "                    fakeact = self._apply_activate(fake)\n",
    "\n",
    "                    real = torch.from_numpy(real.astype('float32')).to(self._device)\n",
    "\n",
    "                    if c1 is not None:\n",
    "                        fake_cat = torch.cat([fakeact, c1], dim=1)\n",
    "                        real_cat = torch.cat([real, c2], dim=1)\n",
    "                    else:\n",
    "                        real_cat = real\n",
    "                        fake_cat = fakeact\n",
    "\n",
    "                    y_fake = discriminator(fake_cat)\n",
    "                    y_real = discriminator(real_cat)\n",
    "\n",
    "                    pen = discriminator.calc_gradient_penalty(\n",
    "                        real_cat, fake_cat, self._device, self.pac\n",
    "                    )\n",
    "                    loss_d = -(torch.mean(y_real) - torch.mean(y_fake))\n",
    "\n",
    "                    optimizerD.zero_grad(set_to_none=False)\n",
    "                    pen.backward(retain_graph=True)\n",
    "                    loss_d.backward()\n",
    "                    optimizerD.step()\n",
    "\n",
    "                fakez = torch.normal(mean=mean, std=std)\n",
    "                condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
    "\n",
    "                if condvec is None:\n",
    "                    c1, m1, col, opt = None, None, None, None\n",
    "                else:\n",
    "                    c1, m1, col, opt = condvec\n",
    "                    c1 = torch.from_numpy(c1).to(self._device)\n",
    "                    m1 = torch.from_numpy(m1).to(self._device)\n",
    "                    fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "                fake = self._generator(fakez)\n",
    "                fakeact = self._apply_activate(fake)\n",
    "\n",
    "                if c1 is not None:\n",
    "                    y_fake = discriminator(torch.cat([fakeact, c1], dim=1))\n",
    "                else:\n",
    "                    y_fake = discriminator(fakeact)\n",
    "\n",
    "                if condvec is None:\n",
    "                    cross_entropy = 0\n",
    "                else:\n",
    "                    cross_entropy = self._cond_loss(fake, c1, m1)\n",
    "\n",
    "                loss_g = -torch.mean(y_fake) + cross_entropy\n",
    "\n",
    "                optimizerG.zero_grad(set_to_none=False)\n",
    "                loss_g.backward()\n",
    "                optimizerG.step()\n",
    "\n",
    "            generator_loss = loss_g.detach().cpu().item()\n",
    "            discriminator_loss = loss_d.detach().cpu().item()\n",
    "\n",
    "            epoch_loss_df = pd.DataFrame({\n",
    "                'Epoch': [i],\n",
    "                'Generator Loss': [generator_loss],\n",
    "                'Discriminator Loss': [discriminator_loss],\n",
    "            })\n",
    "            if not self.loss_values.empty:\n",
    "                self.loss_values = pd.concat([self.loss_values, epoch_loss_df]).reset_index(\n",
    "                    drop=True\n",
    "                )\n",
    "            else:\n",
    "                self.loss_values = epoch_loss_df\n",
    "\n",
    "            if self._verbose:\n",
    "                epoch_iterator.set_description(\n",
    "                    description.format(gen=generator_loss, dis=discriminator_loss)\n",
    "                )\n",
    "        self._discriminator = discriminator\n",
    "\n",
    "    @random_state\n",
    "    def sample(self, n, condition_column=None, condition_value=None):\n",
    "        \"\"\"Sample data similar to the training data.\n",
    "\n",
    "        Choosing a condition_column and condition_value will increase the probability of the\n",
    "        discrete condition_value happening in the condition_column.\n",
    "\n",
    "        Args:\n",
    "            n (int):\n",
    "                Number of rows to sample.\n",
    "            condition_column (string):\n",
    "                Name of a discrete column.\n",
    "            condition_value (string):\n",
    "                Name of the category in the condition_column which we wish to increase the\n",
    "                probability of happening.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray or pandas.DataFrame\n",
    "        \"\"\"\n",
    "        if condition_column is not None and condition_value is not None:\n",
    "            condition_info = self._transformer.convert_column_name_value_to_id(\n",
    "                condition_column, condition_value\n",
    "            )\n",
    "            global_condition_vec = self._data_sampler.generate_cond_from_condition_column_info(\n",
    "                condition_info, self._batch_size\n",
    "            )\n",
    "        else:\n",
    "            global_condition_vec = None\n",
    "\n",
    "        steps = n // self._batch_size + 1\n",
    "        data = []\n",
    "        for i in range(steps):\n",
    "            mean = torch.zeros(self._batch_size, self._embedding_dim)\n",
    "            std = mean + 1\n",
    "            fakez = torch.normal(mean=mean, std=std).to(self._device)\n",
    "\n",
    "            if global_condition_vec is not None:\n",
    "                condvec = global_condition_vec.copy()\n",
    "            else:\n",
    "                condvec = self._data_sampler.sample_original_condvec(self._batch_size)\n",
    "\n",
    "            if condvec is None:\n",
    "                pass\n",
    "            else:\n",
    "                c1 = condvec\n",
    "                c1 = torch.from_numpy(c1).to(self._device)\n",
    "                fakez = torch.cat([fakez, c1], dim=1)\n",
    "\n",
    "            fake = self._generator(fakez)\n",
    "            fakeact = self._apply_activate(fake)\n",
    "            data.append(fakeact.detach().cpu().numpy())\n",
    "\n",
    "        data = np.concatenate(data, axis=0)\n",
    "        data = data[:n]\n",
    "\n",
    "        return self._transformer.inverse_transform(data)\n",
    "\n",
    "    def set_device(self, device):\n",
    "        \"\"\"Set the `device` to be used ('GPU' or 'CPU).\"\"\"\n",
    "        self._device = device\n",
    "        if self._generator is not None:\n",
    "            self._generator.to(self._device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hj/pbs977kd43s6n1l9z3mxrj200000gn/T/ipykernel_52757/2448480046.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ctgan = torch.load(\"./model.pth\", map_location=torch.device('cpu'))\n",
      "/Users/yegortrussov/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator BayesianGaussianMixture from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ctgan = torch.load(\"./model.pth\", map_location=torch.device('cpu'))\n",
    "wallets_features = pd.read_csv(\"../dataset/custom/train_test_split/wallets_features_aggregated__train.csv\")\n",
    "# wallets_features.head()\n",
    "wallets_features_licit = wallets_features[wallets_features[\"class\"] == 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_timesteps_appeared_in</th>\n",
       "      <th>fees_median</th>\n",
       "      <th>num_addr_transacted_multiple</th>\n",
       "      <th>addr_gini</th>\n",
       "      <th>num_txs_as_sender</th>\n",
       "      <th>num_txs_as receiver</th>\n",
       "      <th>lifetime_in_blocks</th>\n",
       "      <th>btc_transacted_total</th>\n",
       "      <th>btc_sent_total</th>\n",
       "      <th>btc_received_total</th>\n",
       "      <th>...</th>\n",
       "      <th>btc_transacted_min</th>\n",
       "      <th>btc_sent_min</th>\n",
       "      <th>btc_received_min</th>\n",
       "      <th>fees_min</th>\n",
       "      <th>transacted_w_address_min</th>\n",
       "      <th>btc_transacted_max</th>\n",
       "      <th>btc_sent_max</th>\n",
       "      <th>btc_received_max</th>\n",
       "      <th>fees_max</th>\n",
       "      <th>transacted_w_address_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>-5.016119e-05</td>\n",
       "      <td>-1.727833</td>\n",
       "      <td>0.599189</td>\n",
       "      <td>-26.865816</td>\n",
       "      <td>-0.918681</td>\n",
       "      <td>0.699086</td>\n",
       "      <td>9.159079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>1.000432</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.034158</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>1.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>-0.006482</td>\n",
       "      <td>2.976255e-04</td>\n",
       "      <td>2.281156</td>\n",
       "      <td>0.235522</td>\n",
       "      <td>122.126513</td>\n",
       "      <td>-3.740948</td>\n",
       "      <td>2.465696</td>\n",
       "      <td>7.140991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>1.000056</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>-0.033485</td>\n",
       "      <td>-0.006912</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.999860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.003395</td>\n",
       "      <td>1.246990e-07</td>\n",
       "      <td>3.829095</td>\n",
       "      <td>2.922266</td>\n",
       "      <td>404.506539</td>\n",
       "      <td>19.674426</td>\n",
       "      <td>3.362494</td>\n",
       "      <td>7.443175</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016155</td>\n",
       "      <td>-0.027049</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.623062</td>\n",
       "      <td>1.096980</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.999446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999412</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>-0.005569</td>\n",
       "      <td>-1.329922e-04</td>\n",
       "      <td>-2.669393</td>\n",
       "      <td>0.466812</td>\n",
       "      <td>104.593343</td>\n",
       "      <td>-10.317670</td>\n",
       "      <td>-8.054022</td>\n",
       "      <td>-0.242375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816337</td>\n",
       "      <td>2.854105</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>1.000249</td>\n",
       "      <td>0.537283</td>\n",
       "      <td>0.918523</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>1.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000418</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.004250</td>\n",
       "      <td>-5.606261e-05</td>\n",
       "      <td>2.871705</td>\n",
       "      <td>0.567066</td>\n",
       "      <td>-51.997455</td>\n",
       "      <td>-12.344783</td>\n",
       "      <td>-2.967022</td>\n",
       "      <td>-4.003370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033409</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1.000326</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>1.000218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_timesteps_appeared_in  fees_median  num_addr_transacted_multiple  \\\n",
       "0                   0.999394     0.000988                      0.004119   \n",
       "1                   0.999737     0.000937                     -0.006482   \n",
       "2                   0.999852     0.001869                      0.003395   \n",
       "3                   0.999412     0.004639                     -0.005569   \n",
       "4                   1.000418     0.001176                     -0.004250   \n",
       "\n",
       "      addr_gini  num_txs_as_sender  num_txs_as receiver  lifetime_in_blocks  \\\n",
       "0 -5.016119e-05          -1.727833             0.599189          -26.865816   \n",
       "1  2.976255e-04           2.281156             0.235522          122.126513   \n",
       "2  1.246990e-07           3.829095             2.922266          404.506539   \n",
       "3 -1.329922e-04          -2.669393             0.466812          104.593343   \n",
       "4 -5.606261e-05           2.871705             0.567066          -51.997455   \n",
       "\n",
       "   btc_transacted_total  btc_sent_total  btc_received_total  ...  \\\n",
       "0             -0.918681        0.699086            9.159079  ...   \n",
       "1             -3.740948        2.465696            7.140991  ...   \n",
       "2             19.674426        3.362494            7.443175  ...   \n",
       "3            -10.317670       -8.054022           -0.242375  ...   \n",
       "4            -12.344783       -2.967022           -4.003370  ...   \n",
       "\n",
       "   btc_transacted_min  btc_sent_min  btc_received_min  fees_min  \\\n",
       "0            0.025676     -0.002059         -0.000072  0.000740   \n",
       "1            0.003129      0.051604         -0.000165  0.000795   \n",
       "2            1.016155     -0.027049         -0.001771  0.000376   \n",
       "3            0.816337      2.854105         -0.000831  0.002064   \n",
       "4            0.033409      0.019186          0.000012  0.000461   \n",
       "\n",
       "   transacted_w_address_min  btc_transacted_max  btc_sent_max  \\\n",
       "0                  1.000432           -0.004355     -0.034158   \n",
       "1                  1.000056           -0.000190     -0.033485   \n",
       "2                  0.999762            0.623062      1.096980   \n",
       "3                  1.000249            0.537283      0.918523   \n",
       "4                  1.000326            0.035708      0.035816   \n",
       "\n",
       "   btc_received_max  fees_max  transacted_w_address_max  \n",
       "0          0.003125  0.000708                  1.000539  \n",
       "1         -0.006912  0.001080                  0.999860  \n",
       "2          0.998625  0.002261                  0.999446  \n",
       "3          0.018901  0.002087                  1.000196  \n",
       "4          0.009915  0.001669                  1.000218  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled = ctgan.sample(1000)\n",
    "sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# wallets_features_licit[col].hist(ax=ax)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# sampled[col].hist(ax=ax)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mplot_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_txs_as_sender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m, in \u001b[0;36mplot_values\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_values\u001b[39m(col):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# print(sampled[col])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# sns.histplot(wallets_features_licit[col])\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# sns.histplot(sampled[col])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwallets_features_licit\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprobability\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     sns\u001b[38;5;241m.\u001b[39mhistplot(sampled[col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), stat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax\u001b[38;5;241m=\u001b[39max)\n\u001b[1;32m     11\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_xticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/seaborn/distributions.py:1416\u001b[0m, in \u001b[0;36mhistplot\u001b[0;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1405\u001b[0m estimate_kws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1406\u001b[0m     stat\u001b[38;5;241m=\u001b[39mstat,\n\u001b[1;32m   1407\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1411\u001b[0m     cumulative\u001b[38;5;241m=\u001b[39mcumulative,\n\u001b[1;32m   1412\u001b[0m )\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39munivariate:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_univariate_histogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshrink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkde_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkde_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimate_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimate_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     p\u001b[38;5;241m.\u001b[39mplot_bivariate_histogram(\n\u001b[1;32m   1435\u001b[0m         common_bins\u001b[38;5;241m=\u001b[39mcommon_bins,\n\u001b[1;32m   1436\u001b[0m         common_norm\u001b[38;5;241m=\u001b[39mcommon_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1447\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/seaborn/distributions.py:571\u001b[0m, in \u001b[0;36m_DistributionPlotter.plot_univariate_histogram\u001b[0;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m element \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbars\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    567\u001b[0m \n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# Use matplotlib bar plotting\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     plot_func \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mbar \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_variable \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mbarh\n\u001b[0;32m--> 571\u001b[0m     artists \u001b[38;5;241m=\u001b[39m \u001b[43mplot_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheights\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwidths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43martist_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_variable \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_axes.py:2510\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2508\u001b[0m x0 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m   2509\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_xunits(x))\n\u001b[0;32m-> 2510\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_dx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_xunits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2512\u001b[0m     xerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(xerr, x0, x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_xunits)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_axes.py:2316\u001b[0m, in \u001b[0;36mAxes._convert_dx\u001b[0;34m(dx, x0, xconv, convert)\u001b[0m\n\u001b[1;32m   2314\u001b[0m     dx \u001b[38;5;241m=\u001b[39m [dx]\n\u001b[1;32m   2315\u001b[0m     delist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 2316\u001b[0m dx \u001b[38;5;241m=\u001b[39m [convert(x0 \u001b[38;5;241m+\u001b[39m ddx) \u001b[38;5;241m-\u001b[39m x \u001b[38;5;28;01mfor\u001b[39;00m ddx \u001b[38;5;129;01min\u001b[39;00m dx]\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delist:\n\u001b[1;32m   2318\u001b[0m     dx \u001b[38;5;241m=\u001b[39m dx[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axes/_axes.py:2316\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2314\u001b[0m     dx \u001b[38;5;241m=\u001b[39m [dx]\n\u001b[1;32m   2315\u001b[0m     delist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 2316\u001b[0m dx \u001b[38;5;241m=\u001b[39m [\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mddx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m x \u001b[38;5;28;01mfor\u001b[39;00m ddx \u001b[38;5;129;01min\u001b[39;00m dx]\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delist:\n\u001b[1;32m   2318\u001b[0m     dx \u001b[38;5;241m=\u001b[39m dx[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/artist.py:279\u001b[0m, in \u001b[0;36mArtist.convert_xunits\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ax\u001b[38;5;241m.\u001b[39mxaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/axis.py:1804\u001b[0m, in \u001b[0;36mAxis.convert_units\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_units\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m   1803\u001b[0m     \u001b[38;5;66;03m# If x is natively supported by Matplotlib, doesn't need converting\u001b[39;00m\n\u001b[0;32m-> 1804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmunits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_natively_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1805\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/matplotlib/units.py:62\u001b[0m, in \u001b[0;36m_is_natively_supported\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mReturn whether *x* is of a type that Matplotlib natively supports or an\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03marray of objects of such types.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Matplotlib natively supports all number types except Decimal.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39miterable(x):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Assume lists are homogeneous as other functions in unit system.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thisx \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m thisx \u001b[38;5;129;01mis\u001b[39;00m ma\u001b[38;5;241m.\u001b[39mmasked:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(col):\n",
    "    # print(sampled[col])\n",
    "    # sns.histplot(wallets_features_licit[col])\n",
    "    # sns.histplot(sampled[col])\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.histplot(wallets_features_licit[col].astype(int), stat=\"probability\", ax=ax)\n",
    "    sns.histplot(sampled[col].astype(int), stat=\"probability\", ax=ax)\n",
    "    ax.set_xticks(range(1,10))\n",
    "    plt.show()\n",
    "    # wallets_features_licit[col].hist(ax=ax)\n",
    "    # sampled[col].hist(ax=ax)\n",
    "    \n",
    "plot_values(\"num_txs_as_sender\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled[\"num_txs_as_sender\"].hist()\n",
    "# wallets_features_licit[\"num_txs_as_sender\"].astype(int).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
